# ğŸ¬ Movie Data Pipeline Project

## ğŸ“Œ Overview

This project demonstrates a complete end-to-end data pipeline built using AWS and Snowflake. The pipeline extracts movie-related data from an external source (DB/API), processes and transforms the data, and loads it into Snowflake for analytics and dashboarding. It also includes monitoring and alerting mechanisms, with potential enhancements for building a dimensional model using SCD techniques.

![image](https://github.com/user-attachments/assets/a1242d1a-9afc-4c30-9be9-84457214cdc8)



---

## ğŸ—ï¸ Architecture

ğŸ“¡ Source Layer
    â‡¨ Movie data pulled from external DB/API

ğŸ“¦ Ingestion & Staging
    â‡¨ Data converted to CSV & Parquet
    â‡¨ Manifest file generated
    â‡¨ Files zipped and uploaded to S3 (Landing Zone)

âš™ï¸ Processing & Transformation
    â‡¨ Lambda unzips and validates files
    â‡¨ AWS Glue (Spark) transforms and validates data

ğŸ Load & Storage
    â‡¨ Transformed data stored in S3 (Archive)
    â‡¨ Snowpipe ingests data into Snowflake

ğŸ“Š Consumption & Monitoring
    â‡¨ Dashboards via Power BI / Tableau
    â‡¨ Logs via CloudWatch
    â‡¨ Alerts via SNS (Email notifications)





âš™ï¸ Components
ğŸ”„ Data Ingestion
Source: External DB/API with movie info

Format: Converted to CSV and Parquet

Metadata: Manifest file created

Compression: CSV + Manifest zipped

â˜ï¸ AWS S3
Landing Bucket: Stores zipped data

Processed Bucket: Receives unzipped files via Lambda

Archive Bucket: Stores final transformed CSVs

ğŸ§© Lambda Function
Triggered on file upload

Unzips incoming archive

Moves contents to correct S3 location

ğŸ”¥ AWS Glue Job
Spark-based transformation of CSV/Parquet

Data cleansing and enrichment

Writes output as CSV into the archive bucket

â„ï¸ Snowflake Integration
Snowpipe monitors archive bucket

Automatically loads transformed data into target tables

ğŸ“Š Consumption Layer
Snowflake tables form the base for dashboards

Compatible with Power BI, Tableau, and other BI tools

ğŸš¨ Monitoring & Alerting
CloudWatch for logging Glue/Lambda

AWS SNS for failure notifications to registered email addresses

ğŸŒŸ Future Enhancements
Implement star/snowflake schema in Snowflake

Enable SCD Type 1 / Type 2 using Snowflake Streams and Tasks

Add unit tests & CI/CD pipeline for Lambda and Glue jobs

Cost optimization by moving infrequent data to Glacier

Enhance metadata tracking using AWS Glue Data Catalog or custom metadata store



ğŸ“ Project Structure

```plaintext
project-root/
â”œâ”€â”€ lambda/
â”‚   â”œâ”€â”€ Extract.py                    # API/DB data extractor in this file itself we are generating the manifest file
â”‚   â”œâ”€â”€ Zipping.py                    # Zips files and manifest
â”‚   â””â”€â”€ Trigger_job.py                # Triggers Glue job
â”œâ”€â”€ glue_jobs/
â”‚   â””â”€â”€ transform_movies.py           # Spark ETL script in AWS Glue
â”œâ”€â”€ Sample_data/
â”‚   â”œâ”€â”€ Raw_movie_data.csv            # Raw sample data
â”‚   â”œâ”€â”€ movie_data.parquet            # Parquet version
â”‚   â””â”€â”€ manifest.json                 # Metadata manifest
â”œâ”€â”€ diagrams/
â”‚   â””â”€â”€ architecture.png              # Visual architecture
â”œâ”€â”€ snowflake/
â”‚   â””â”€â”€ Snowflake SQL Commands        # CREATE TABLE + PIPE scripts
â””â”€â”€ README.md                         # Documentation
```
